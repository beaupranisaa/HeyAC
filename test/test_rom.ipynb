{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnRiGTiobzcF"
   },
   "source": [
    "# NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tree import Tree\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "from little_heys import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Grammar\n",
    "#### Problem: Difficult to define our own grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open(\"../grammars/grammar_rom.txt\", \"r\")\n",
    "grammar = nltk.CFG.fromstring(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get synonyms of all the base verbs, nouns and adjectives before passing them to our grammar\n",
    "#### Problem: Hard to define our base verbs, nouns and adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/rom/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "syns = wordnet.synsets(\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_verbs = [\"increase\", \"decrease\", \"swing\", \"set\", \"turn-on\", \n",
    "              \"turn\", \"activate\",\"stop\",\"speed\",\"reduce\",\"raise\",\n",
    "              \"pause\",\"lower\",\"dry\" ]\n",
    "base_props = [\"temperature\", \"humidity\",\"heat\" ,\"speed\"]\n",
    "base_objs = [\"fan\",\"air\",\"room\",\"air-conditioner\"]\n",
    "base_adjs = [\"cold\", \"hot\", \"windy\",\"high\",\"low\",\"dry\",\"humid\"]\n",
    "\n",
    "bases = [base_verbs, base_props, base_objs, base_adjs]\n",
    "base_names = [\"base_verbs\", \"base_props\", \"base_objs\", \"base_adjs\"]\n",
    "\n",
    "verb_net = { key : [key] for key in base_verbs}\n",
    "props_net = { key : [key] for key in base_props}\n",
    "objs_net = { key: [key] for key in base_objs}\n",
    "adj_net = { key : [key] for key in base_adjs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('air.n.03.air'), Lemma('air.n.03.aura'), Lemma('air.n.03.atmosphere')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets(bases[2][1])[2].lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('mystique.n.01'), Synset('note.n.05'), Synset('vibration.n.04')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 0 0\n",
    "#3 0 3\n",
    "wordnet.synsets(bases[2][1])[2].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_all_hypernyms',\n",
       " '_definition',\n",
       " '_examples',\n",
       " '_frame_ids',\n",
       " '_hypernyms',\n",
       " '_instance_hypernyms',\n",
       " '_iter_hypernym_lists',\n",
       " '_lemma_names',\n",
       " '_lemma_pointers',\n",
       " '_lemmas',\n",
       " '_lexname',\n",
       " '_max_depth',\n",
       " '_min_depth',\n",
       " '_name',\n",
       " '_needs_root',\n",
       " '_offset',\n",
       " '_pointers',\n",
       " '_pos',\n",
       " '_related',\n",
       " '_shortest_hypernym_paths',\n",
       " '_wordnet_corpus_reader',\n",
       " 'acyclic_tree',\n",
       " 'also_sees',\n",
       " 'attributes',\n",
       " 'causes',\n",
       " 'closure',\n",
       " 'common_hypernyms',\n",
       " 'definition',\n",
       " 'entailments',\n",
       " 'examples',\n",
       " 'frame_ids',\n",
       " 'hypernym_distances',\n",
       " 'hypernym_paths',\n",
       " 'hypernyms',\n",
       " 'hyponyms',\n",
       " 'in_region_domains',\n",
       " 'in_topic_domains',\n",
       " 'in_usage_domains',\n",
       " 'instance_hypernyms',\n",
       " 'instance_hyponyms',\n",
       " 'jcn_similarity',\n",
       " 'lch_similarity',\n",
       " 'lemma_names',\n",
       " 'lemmas',\n",
       " 'lexname',\n",
       " 'lin_similarity',\n",
       " 'lowest_common_hypernyms',\n",
       " 'max_depth',\n",
       " 'member_holonyms',\n",
       " 'member_meronyms',\n",
       " 'min_depth',\n",
       " 'mst',\n",
       " 'name',\n",
       " 'offset',\n",
       " 'part_holonyms',\n",
       " 'part_meronyms',\n",
       " 'path_similarity',\n",
       " 'pos',\n",
       " 'region_domains',\n",
       " 'res_similarity',\n",
       " 'root_hypernyms',\n",
       " 'shortest_path_distance',\n",
       " 'similar_tos',\n",
       " 'substance_holonyms',\n",
       " 'substance_meronyms',\n",
       " 'topic_domains',\n",
       " 'tree',\n",
       " 'usage_domains',\n",
       " 'verb_groups',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wordnet.synsets(bases[0][0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(bases)):\n",
    "    base = bases[i]\n",
    "    for to_find in base:\n",
    "        for syn in wordnet.synsets(to_find):\n",
    "            for l in syn.lemmas():\n",
    "                if to_find in base_verbs:\n",
    "                    if l.name() not in verb_net[to_find]:\n",
    "                        lemma = lemmatizer.lemmatize(l.name(), pos ='v')\n",
    "                        verb_net[to_find].append(lemma)\n",
    "                elif to_find in base_nouns:\n",
    "                    if l.name() not in noun_net[to_find]:\n",
    "                        lemma = lemmatizer.lemmatize(l.name(), pos ='n')\n",
    "                        noun_net[to_find].append(lemma)\n",
    "                else:\n",
    "                    if l.name() not in adj_net[to_find]:\n",
    "                        lemma = lemmatizer.lemmatize(l.name(), pos ='a')                        \n",
    "                        adj_net[to_find].append(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noun_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hey AC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hey_ac():\n",
    "    def __init__(self, sent, grammar, var=False):\n",
    "        self.orig_sent = sent\n",
    "        self.sent = None\n",
    "        self.grammar = grammar\n",
    "        \n",
    "        # Convert words to numbers\n",
    "        self.var = var\n",
    "        if self.var == True:\n",
    "            self.sent = self.sent.split()\n",
    "            self.sent = [ \"hey_num\" if i.isdigit() else i for i in self.sent]\n",
    "            self.sent = ' '.join(self.sent)\n",
    "        \n",
    "        self.parsed = self.parsed.lower() #Increase TeMpeRATure -> increase temperature\n",
    "        self.parsed = self.parsed.correct() # increese -> increase\n",
    "        \n",
    "        self.sent_prep = []\n",
    "\n",
    "    def lemmatization(self):\n",
    "        # Lemmatization\n",
    "        for i in range(len(self.parsed.words)):\n",
    "            # lemmatization: colder -> cold \n",
    "            # pos = 'a' --> adj, 'v' --> verb, 'n' -> noun\n",
    "            lemma = lemmatizer.lemmatize(self.parsed.words[i], pos ='a')\n",
    "            lemma = lemmatizer.lemmatize(lemma, pos ='v')\n",
    "            lemma = lemmatizer.lemmatize(lemma, pos ='n')\n",
    "            # lemmatization: increases -> increase\n",
    "            lemma = lemmatizer.lemmatize(lemma)\n",
    "            self.sent_prep.append(lemma)\n",
    "        \n",
    "        # if contains 'please', remove\n",
    "        if 'please' in self.sent_prep:\n",
    "            self.sent_prep.remove('please')\n",
    "            return self.sent_prep\n",
    "        else:\n",
    "            return self.sent_prep\n",
    "    \n",
    "    def wordnet(self, to_parse):\n",
    "        sent_wordnet = []\n",
    "        self.sent_wordnet_orig = len(to_parse)\n",
    "        for word in to_parse:\n",
    "            for k,v in verb_net.items():\n",
    "                if word in v:\n",
    "                    sent_wordnet.append(k)\n",
    "                else:\n",
    "                    pass\n",
    "            for k,v in noun_net.items():\n",
    "                if word in v:\n",
    "                    sent_wordnet.append(k)\n",
    "                else:\n",
    "                    pass\n",
    "            for k,v in adj_net.items():\n",
    "                if word in v:\n",
    "                    sent_wordnet.append(k)\n",
    "                else:\n",
    "                    pass\n",
    "            if word in [\"the\",\"a\",\"an\",\"off\",\"down\",\"up\", \"on\",\"to\",\"hey_num\",\"by\", \"from\",\"a.m\",\"at\", \"pm\", \"o'clock\"]:\n",
    "                sent_wordnet.append(word)\n",
    "        if len(sent_wordnet) != self.sent_wordnet_orig:\n",
    "            raise Exception(\"Sorry I do not understand you\")\n",
    "        else:\n",
    "            return sent_wordnet\n",
    "    \n",
    "    \n",
    "    def check(self):\n",
    "        self.to_parse = self.lemmatization()\n",
    "        self.to_parse = self.wordnet(self.to_parse)      \n",
    "        rd_parser = nltk.RecursiveDescentParser(self.grammar)\n",
    "        try:\n",
    "            for p in rd_parser.parse(self.to_parse):\n",
    "                if var == True:\n",
    "                    numbers = [i for i in split([self.orig_sent]) if i.isdigit()]\n",
    "                    for n in numbers:\n",
    "                        p = str(p).replace('hey_num', n, 1)\n",
    "                        self.to_parse = str(self.to_parse).replace('hey_num', n, 1)\n",
    "                        self.to_parse = self.to_parse.strip('][').split(', ')\n",
    "\n",
    "                return self.to_parse, p\n",
    "        except:\n",
    "            raise Exception(\"Sorry I do not understand you\")\n",
    "            \n",
    "            \n",
    "    # Pruning \n",
    "    def classify_me(self):\n",
    "        to_prune, p = self.check()\n",
    "        VB = []\n",
    "        NN = []\n",
    "        CO = []\n",
    "        RP = []\n",
    "        for i in Tree.fromstring(str(p)).subtrees():\n",
    "            if i.label() == 'VB':\n",
    "                VB.append(i.leaves()[0])\n",
    "            elif i.label() == 'NN':\n",
    "                NN.append(i.leaves()[0])\n",
    "            elif i.label() == 'CO':\n",
    "                CO.append(i.leaves()[0])\n",
    "            elif i.label() == 'RP':\n",
    "                RP.append(i.leaves()[0])\n",
    "        print('Use me to classify: ')\n",
    "        print('VB', VB)\n",
    "        print('NN', NN)\n",
    "        print('CO', CO)\n",
    "        print('RP', RP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "User:  Please turn up the heat\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['turn']\n",
      "NN ['heat']\n",
      "CO []\n",
      "RP ['up']\n",
      "==================================================\n",
      "User:  turn the air-condition off please\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['turn']\n",
      "NN ['air-condition']\n",
      "CO []\n",
      "RP ['off']\n",
      "==================================================\n",
      "User:  turn on the fan mode\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['turn']\n",
      "NN ['fan', 'mode']\n",
      "CO []\n",
      "RP ['on']\n",
      "==================================================\n",
      "User:  turn off the fan\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['turn']\n",
      "NN ['fan']\n",
      "CO []\n",
      "RP ['off']\n",
      "==================================================\n",
      "User:  swing up the air\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['swing']\n",
      "NN ['air']\n",
      "CO []\n",
      "RP ['up']\n",
      "==================================================\n",
      "User:  swing the air-condition\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['swing']\n",
      "NN ['air-condition']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  stop the swing\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['stop']\n",
      "NN ['swing']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  speed up the fan\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['speed']\n",
      "NN ['fan']\n",
      "CO []\n",
      "RP ['up']\n",
      "==================================================\n",
      "User:  reduce the temperature\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['reduce']\n",
      "NN ['temperature']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  raise the temperature by 3 degrees\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['raise']\n",
      "NN ['temperature']\n",
      "CO ['3']\n",
      "RP []\n",
      "==================================================\n",
      "User:  pause the swing\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['pause']\n",
      "NN ['swing']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  increase the humidity\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['increase']\n",
      "NN ['humidity']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  increase the fan speed\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['increase']\n",
      "NN ['fan', 'speed']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  activate the fan mode\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['activate']\n",
      "NN ['fan', 'mode']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  lower the fan speed\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['lower']\n",
      "NN ['fan', 'speed']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  lower the air\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['lower']\n",
      "NN ['air']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  dry the room\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['dry']\n",
      "NN ['room']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  decrease the humidity\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['decrease']\n",
      "NN ['humidity']\n",
      "CO []\n",
      "RP []\n",
      "==================================================\n",
      "User:  turn on the air-condition from twenty-four pm to one o'clock\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['turn']\n",
      "NN ['air-condition']\n",
      "CO ['24', '1']\n",
      "RP []\n",
      "==================================================\n",
      "User:  please increase the temperature by twenty-five degrees\n",
      "==================================================\n",
      "Use me to classify: \n",
      "VB ['increase']\n",
      "NN ['temperature']\n",
      "CO ['25']\n",
      "RP []\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"the speed of the fan is too high\"\n",
    " ] \n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print('='*50)\n",
    "    sent = sentences[i]\n",
    "    print('User: ',sent)\n",
    "    print('='*50)   \n",
    "    var, sent = check_var(sent)\n",
    "    hey_ac(sent, grammar, var = var).classify_me()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: possible to also convert word->num\n",
    "Still error because of the incomplete grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = \"deecrease the temperature twenty-five degrees\"\n",
    "# hey_ac(sent,grammar, var=True).hey_ac_hey() # variable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.1-nltk.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
